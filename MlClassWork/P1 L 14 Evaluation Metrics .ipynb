{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for this Decision Tree:\n",
      "[[95 42]\n",
      " [33 53]]\n",
      "GaussianNB confusion matrix:\n",
      "[[116  21]\n",
      " [ 46  40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# In this exercise, we'll use the Titanic dataset as before, train two classifiers and\n",
    "# look at their confusion matrices. Your job is to create a train/test split in the data\n",
    "# and report the results in the dictionary at the bottom.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the default settings for train_test_split (or test_size = 0.25 if specified).\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.25)\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(x_train,y_train) \n",
    "Confusion1 = confusion_matrix(y_test,clf1.predict(x_test))\n",
    "print \"Confusion matrix for this Decision Tree:\\n\",Confusion1\n",
    "\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(x_train,y_train) \n",
    "confusion2 = confusion_matrix(y_test,clf2.predict(x_test))\n",
    "print \"GaussianNB confusion matrix:\\n\",confusion2\n",
    "\n",
    "#TODO: store the confusion matrices on the test sets below\n",
    "\n",
    "confusions = {\n",
    " \"Naive Bayes\": confusion2,\n",
    " \"Decision Tree\": Confusion1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Vs Recall\n",
    " As with the previous exercises, let's look at the performance of a couple of classifiers\n",
    " on the familiar Titanic dataset. Add a train/test split, then store the results in the\n",
    " dictionary provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "X = X._get_numeric_data()\n",
    "y = X['Survived']\n",
    "del X['Age'], X['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: split the data into training and testing sets,\n",
    "#### using the standard settings for train_test_split.\n",
    "#### Then, train and test the classifiers with your newly split data instead of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,x_test,y,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree recall: 0.43 and precision: 0.51\n",
      "GaussianNB recall: 0.40 and precision: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72340425531914898"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X, y)\n",
    "DTC = recall(y_test,clf1.predict(x_test)),precision(y_test,clf1.predict(x_test))\n",
    "print \"Decision Tree recall: {:.2f} and precision: {:.2f}\".format(*DTC)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X, y)\n",
    "GNB = recall(y_test,clf2.predict(x_test)),precision(y_test,clf2.predict(x_test))\n",
    "print \"GaussianNB recall: {:.2f} and precision: {:.2f}\".format(*GNB)\n",
    "GNB[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute F1 Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree F1 score: 0.50\n",
      "GaussianNB F1 score: 0.47\n"
     ]
    }
   ],
   "source": [
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X, y)\n",
    "DTC = f1_score(y_test, clf1.predict(x_test))\n",
    "print \"Decision Tree F1 score: {:.2f}\".format(DTC)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X, y)\n",
    "GNB = f1_score(y_test, clf2.predict(x_test))\n",
    "print \"GaussianNB F1 score: {:.2f}\".format(GNB)\n",
    "\n",
    "F1_scores = {\n",
    " \"Naive Bayes\": GNB,\n",
    " \"Decision Tree\": DTC\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Mean Absolute Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "linnerud_data = load_linnerud()\n",
    "X = linnerud_data.data\n",
    "y = linnerud_data.target\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: split the data into training and testing sets,\n",
    "    using the standard settings for train_test_split.\n",
    " Then, train and test the classifiers with your newly split data instead of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 7.80\n"
     ]
    }
   ],
   "source": [
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(x_train, y_train)\n",
    "dtm = mae(y_test,reg1.predict(x_test))\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression mean absolute error: 7.52\n"
     ]
    }
   ],
   "source": [
    "reg2 = LinearRegression()\n",
    "reg2.fit(x_train, y_train)\n",
    "lrm = mae(y_test,reg2.predict(x_test))\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {\n",
    " \"Linear Regression\": lrm,\n",
    " \"Decision Tree\": dtm\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Mean Squared Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree mean absolute error: 363.20\n",
      "Linear regression mean absolute error: 362.12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "reg1 = DecisionTreeRegressor()\n",
    "reg1.fit(x_train, y_train)\n",
    "dtm = mse(y_test,reg1.predict(x_test))\n",
    "print \"Decision Tree mean absolute error: {:.2f}\".format(dtm)\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(x_train, y_train)\n",
    "lrm = mse(y_test,reg2.predict(x_test))\n",
    "print \"Linear regression mean absolute error: {:.2f}\".format(lrm)\n",
    "\n",
    "results = {\n",
    " \"Linear Regression\": lrm,\n",
    " \"Decision Tree\": dtm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
